{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef531df",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {\n",
    "    \"artifacts\": {\n",
    "        \"imputed_dataset_path\": {\n",
    "            \"artifacts\": [{\n",
    "                \"name\": \"projects/49985438948/locations/us-central1/metadataStores/default/artifacts/6811526190828747751\",\n",
    "                \"uri\": \"gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/train-imputation_-3274262545669554176/imputed_dataset_path\",\n",
    "                \"metadata\": {}\n",
    "            }]\n",
    "        },\n",
    "        \"mean_a1c_dia\": {\n",
    "            \"artifacts\": [{\n",
    "                \"name\": \"projects/49985438948/locations/us-central1/metadataStores/default/artifacts/1438184060222455176\",\n",
    "                \"uri\": \"gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/train-imputation_-3274262545669554176/mean_a1c_dia\",\n",
    "                \"metadata\": {\"value\": 2.1493724929514166}\n",
    "            }]\n",
    "        },\n",
    "        \"mean_a1c_nondia\": {\n",
    "            \"artifacts\": [{\n",
    "                \"name\": \"projects/49985438948/locations/us-central1/metadataStores/default/artifacts/16561020661929813690\",\n",
    "                \"uri\": \"gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/train-imputation_-3274262545669554176/mean_a1c_nondia\",\n",
    "                \"metadata\": {\"value\": 1.6347599082650512}\n",
    "            }]\n",
    "        },\n",
    "        \"mean_saved\": {\n",
    "            \"artifacts\": [{\n",
    "                \"name\": \"projects/49985438948/locations/us-central1/metadataStores/default/artifacts/12794769974312219209\",\n",
    "                \"uri\": \"gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/train-imputation_-3274262545669554176/mean_saved\",\n",
    "                \"metadata\": {\"value\": {\"log_tot_chol\": 5.45446608070892, \"log_bmi\": 3.2765795514207583, \"heartRate\": 75.75385119632907}}\n",
    "            }]\n",
    "        },\n",
    "        \"mode_cigs\": {\n",
    "            \"artifacts\": [{\n",
    "                \"name\": \"projects/49985438948/locations/us-central1/metadataStores/default/artifacts/16704505771573258107\",\n",
    "                \"uri\": \"gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/train-imputation_-3274262545669554176/mode_cigs\",\n",
    "                \"metadata\": {\"value\": 20.0}\n",
    "            }]\n",
    "        },\n",
    "        \"mode_saved\": {\n",
    "            \"artifacts\": [{\n",
    "                \"name\": \"projects/49985438948/locations/us-central1/metadataStores/default/artifacts/4211559894150523597\",\n",
    "                \"uri\": \"gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/train-imputation_-3274262545669554176/mode_saved\",\n",
    "                \"metadata\": {\"value\": {\"BPMeds\": 0.0, \"education\": 1.0}}\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0fa358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.dsl import OutputPath, InputPath, component\n",
    "from kfp.dsl import pipeline, Output, Dataset\n",
    "@component(packages_to_install=['pandas','numpy','fsspec','gcsfs'])\n",
    "def perform_initial_data_prep(input_dataset_path: str,\n",
    "                              output_dataset_path: OutputPath('Dataset')):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    df=pd.read_csv(input_dataset_path)\n",
    "    \n",
    "    #feature selection\n",
    "    df = df.drop('glucose', axis=1)\n",
    "    \n",
    "    #log transform\n",
    "    df['log_bmi'] = np.log(df['BMI']+1)\n",
    "    df['log_tot_chol'] = np.log(df['totChol']+1)\n",
    "    df['log_sysbp'] = np.log(df['sysBP']+1)\n",
    "    df['log_a1c'] = np.log(df['a1c']+1)\n",
    "    df=df.drop('BMI',axis=1)\n",
    "    df=df.drop('totChol',axis=1)\n",
    "    df=df.drop('sysBP',axis=1)\n",
    "    df=df.drop('a1c',axis=1)\n",
    "    \n",
    "    df.to_csv(output_dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c6a1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data imputation\n",
    "@component(packages_to_install=[\"pandas\"])\n",
    "def test_imputation(test_dataset_path: InputPath('Dataset'),\n",
    "                    imputed_dataset_path: OutputPath('Dataset'),\n",
    "                    mean_saved: dict,\n",
    "                    mode_saved: dict,\n",
    "                    mode_cigs: float,\n",
    "                    a1c_mean_dia: float,\n",
    "                    a1c_mean_nondia: float):\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Load test dataset\n",
    "    df = pd.read_csv(test_dataset_path)\n",
    "    \n",
    "    # Apply mean and mode imputations\n",
    "    for col, value in mean_saved.items():\n",
    "        df[col].fillna(value, inplace=True)\n",
    "    for col, value in mode_saved.items():\n",
    "        df[col].fillna(value, inplace=True)\n",
    "    df.loc[(df['cigsPerDay'].isnull()) & (df['currentSmoker'] == 0), 'cigsPerDay'] = 0\n",
    "    df.loc[(df['cigsPerDay'].isnull()) & (df['currentSmoker'] == 1), 'cigsPerDay'] = mode_cigs\n",
    "\n",
    "    # Apply A1C imputation\n",
    "    df.loc[(df['log_a1c'].isnull()) & (df['diabetes'] == 1), 'log_a1c'] = a1c_mean_dia\n",
    "    df.loc[(df['log_a1c'].isnull()) & (df['diabetes'] == 0), 'log_a1c'] = a1c_mean_nondia\n",
    "    \n",
    "    # Save the imputed dataframe\n",
    "    df.to_csv(imputed_dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cde1256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data engineering\n",
    "@component(packages_to_install=[\"pandas\", \"numpy\", \"scikit-learn\",\"joblib\",'fsspec','gcsfs'])\n",
    "def test_engineering(test_dataset_path: InputPath('Dataset'),\n",
    "                     updated_test_path: OutputPath('Dataset'),\n",
    "                     scaler_path: str,\n",
    "                     cluster_path: str,\n",
    "                     drop_originals: bool = True):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.cluster import KMeans\n",
    "    import gcsfs\n",
    "\n",
    "    # Load test dataset\n",
    "    df_test = pd.read_csv(test_dataset_path)\n",
    "    \n",
    "    fs=gcsfs.GCSFileSystem()\n",
    "\n",
    "    # Load scaler and k-means models\n",
    "    with fs.open(scaler_path,'rb') as f:\n",
    "        scaler = joblib.load(f)\n",
    "    with fs.open(cluster_path,'rb') as f:\n",
    "        kmeans = joblib.load(f)    \n",
    "\n",
    "    # Apply scaling\n",
    "    features_to_scale = ['age', 'education', 'income']\n",
    "    data_scaled = scaler.transform(df_test[features_to_scale])\n",
    "\n",
    "    # Apply clustering\n",
    "    clusters = kmeans.predict(data_scaled)\n",
    "    df_test['Demographic Cluster'] = clusters\n",
    "\n",
    "    # Optionally drop original features\n",
    "    if drop_originals:\n",
    "        df_test.drop(features_to_scale, axis=1, inplace=True)\n",
    "\n",
    "    # Save the updated dataframe\n",
    "    df_test.to_csv(updated_test_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc35a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yufeizhang/anaconda3/lib/python3.11/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: Python 3.7 has reached end-of-life. The default base_image used by the @dsl.component decorator will switch from 'python:3.7' to 'python:3.8' on April 23, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.8.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "@component(packages_to_install=[\"pandas\", \"numpy\", \"scikit-learn\",\"joblib\",'fsspec','gcsfs',\"xgboost\"])\n",
    "def perform_prediction(dataset_for_predict:InputPath('Dataset'),\n",
    "                       model_path:str,\n",
    "                       predictions_path:OutputPath('Dataset')\n",
    "                      ):\n",
    "    import pandas as pd\n",
    "    import joblib\n",
    "    from sklearn.ensemble import VotingClassifier\n",
    "    import gcsfs\n",
    "\n",
    "    fs=gcsfs.GCSFileSystem()\n",
    "    \n",
    "    # Load the test dataset\n",
    "    pred_df = pd.read_csv(dataset_for_predict)\n",
    "    pred_df_x=pred_df.drop('patientID',axis=1)\n",
    "\n",
    "\n",
    "    # Load the ensemble model\n",
    "    with fs.open(model_path,'rb') as f:\n",
    "        trainde_model=joblib.load(f)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = trainde_model.predict(pred_df_x)\n",
    "    pred_df['pred_TenYearCHD']=y_pred\n",
    "    pred_df=pred_df[['patientID','pred_TenYearCHD']]\n",
    "    \n",
    "    pred_df.to_csv(predictions_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2aff98c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the path\n",
    "kmean_cluster_path='gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/scale-and-cluster-train-data_-2121341041062707200/kmeans_path'\n",
    "scaler_path='gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503233914/scale-and-cluster-train-data_-2121341041062707200/scaler_path'\n",
    "model_path='gs://ise543-module8-hw-yufei/49985438948/final-project-pipeline-20240503234919/train-voting-ensemble_5219526351551201280/output_ensemble_model'\n",
    "\n",
    "a1c_mean_dia = json_data['artifacts']['mean_a1c_dia']['artifacts'][0]['metadata']['value']\n",
    "a1c_mean_nondia = json_data['artifacts']['mean_a1c_nondia']['artifacts'][0]['metadata']['value']\n",
    "mean_saved = json_data['artifacts']['mean_saved']['artifacts'][0]['metadata']['value']\n",
    "mode_cigs = json_data['artifacts']['mode_cigs']['artifacts'][0]['metadata']['value']\n",
    "mode_saved = json_data['artifacts']['mode_saved']['artifacts'][0]['metadata']['value']\n",
    "\n",
    "@pipeline(name='final_inference_pipeline')\n",
    "def final_inference_pipeline(dataset_for_prediction: str,\n",
    "                             a1c_mean_dia: float=a1c_mean_dia,\n",
    "                             a1c_mean_nondia: float=a1c_mean_nondia,\n",
    "                             mean_saved: dict=mean_saved,\n",
    "                             mode_cigs: float=mode_cigs,\n",
    "                             mode_saved: dict=mode_saved,\n",
    "                             cluster_path: str=kmean_cluster_path,\n",
    "                             scaler_path: str=scaler_path,\n",
    "                             model_path: str=model_path\n",
    "                             ):\n",
    "\n",
    "    initial_pre_dataset=perform_initial_data_prep(input_dataset_path=dataset_for_prediction)\n",
    "    \n",
    "    imputed_data=test_imputation(test_dataset_path=initial_pre_dataset.output,\n",
    "                                 mean_saved=mean_saved,\n",
    "                                 mode_saved=mode_saved,\n",
    "                                 mode_cigs=mode_cigs,\n",
    "                                 a1c_mean_dia=a1c_mean_dia,\n",
    "                                 a1c_mean_nondia=a1c_mean_nondia\n",
    "                                )\n",
    "    \n",
    "    engineered_data=test_engineering(test_dataset_path=imputed_data.output,\n",
    "                                     scaler_path=scaler_path,\n",
    "                                     cluster_path=cluster_path\n",
    "                                    )\n",
    "    \n",
    "    prediction_perform=perform_prediction(dataset_for_predict=engineered_data.output,\n",
    "                                          model_path=model_path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06ca78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "project_id = 'ise543-module8-421223'\n",
    "location = 'us-central1'\n",
    "aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=final_inference_pipeline,\n",
    "    package_path='final_inference_pipeline.json'\n",
    ")\n",
    "\n",
    "\n",
    "pipeline_job = aiplatform.PipelineJob(\n",
    "    display_name='final_inference_pipeline',\n",
    "    template_path='final_inference_pipeline.json',\n",
    "    pipeline_root='gs://ise543-module8-hw-yufei',\n",
    "    parameter_values={\n",
    "        'dataset_for_prediction': 'gs://ise543-module8-hw-yufei/Final Project Evaluation Dataset - Student.csv'},      \n",
    "    enable_caching=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bce7a5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/final-inference-pipeline-20240506180434?project=49985438948\n",
      "PipelineJob projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434 current state:\n",
      "3\n",
      "PipelineJob projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434 current state:\n",
      "3\n",
      "PipelineJob projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434 current state:\n",
      "3\n",
      "PipelineJob projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434 current state:\n",
      "3\n",
      "PipelineJob run completed. Resource name: projects/49985438948/locations/us-central1/pipelineJobs/final-inference-pipeline-20240506180434\n"
     ]
    }
   ],
   "source": [
    "pipeline_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f447614",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_data=pd.read_csv('./score dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0daf1b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientID</th>\n",
       "      <th>pred_TenYearCHD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>189047</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>957019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>208967</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>230935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>186677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>462501</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>802256</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>516993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>618197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>424 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patientID  pred_TenYearCHD\n",
       "0       110399                0\n",
       "1       189047                0\n",
       "2       957019                0\n",
       "3       208967                0\n",
       "4       230935                0\n",
       "..         ...              ...\n",
       "419     186677                0\n",
       "420     462501                1\n",
       "421     802256                0\n",
       "422     516993                1\n",
       "423     618197                1\n",
       "\n",
       "[424 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
